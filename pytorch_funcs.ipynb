{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce4ed0ad-4031-40f0-a560-2aeba045e701",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37589f04-1665-4a37-bcbe-90d513f9d9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe(t):\n",
    "    print()\n",
    "    print(t,t.shape,t.dtype)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788b0986-01b4-4797-b1f3-992af0c5859f",
   "metadata": {},
   "source": [
    "## Functions where a tensor is created from 0 tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0bc92339-df4b-4296-a7d5-91a85d1e9a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor from list [[1, 2, 3], [4, 5, 6]] =======> tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) with shape torch.Size([2, 3]) with dtype torch.int64 with requires_grad False by default\n",
      "Tensor from numpy array [[0.83410477 0.95239414 0.91786261]\n",
      " [0.23167481 0.91089324 0.4643033 ]] =======> tensor([[0.8341, 0.9524, 0.9179],\n",
      "        [0.2317, 0.9109, 0.4643]], dtype=torch.float64) with shape torch.Size([2, 3]) with dtype torch.float64 with requires_grad False by default\n",
      "Tensor from numpy array [[0.83410477 0.95239414 0.91786261]\n",
      " [0.23167481 0.91089324 0.4643033 ]] =======> tensor([[0.8341, 0.9524, 0.9179],\n",
      "        [0.2317, 0.9109, 0.4643]], dtype=torch.float64) with shape torch.Size([2, 3]) with dtype torch.float64 with requires_grad False by default\n"
     ]
    }
   ],
   "source": [
    "#from list\n",
    "l = [[1,2,3],[4,5,6]]\n",
    "a = torch.tensor(l)\n",
    "print(\"Tensor from list\",l, \"=======>\" , a, \"with shape\",a.shape,\"with dtype\",a.dtype,\"with requires_grad\",a.requires_grad,\"by default\")\n",
    "\n",
    "#from numpy array\n",
    "n = np.random.rand(2,3)\n",
    "b = torch.tensor(n)\n",
    "print(\"Tensor from numpy array\",n, \"=======>\" , b, \"with shape\",b.shape,\"with dtype\",b.dtype,\"with requires_grad\",b.requires_grad,\"by default\")\n",
    "\n",
    "c = torch.from_numpy(n)\n",
    "print(\"Tensor from numpy array\",n, \"=======>\" , c, \"with shape\",c.shape,\"with dtype\",c.dtype,\"with requires_grad\",c.requires_grad,\"by default\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8136d1a9-0ef1-4216-acbd-49b908225388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) torch.Size([2, 3]) torch.float32\n",
      "\n",
      "\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) torch.Size([2, 3]) torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#takes in dims\n",
    "describe(torch.zeros(2,3))\n",
    "#takes in dims\n",
    "describe(torch.ones(2,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44ed2a9a-a7c2-4386-a976-aa1795b76403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[0.4064, 0.7071, 0.6499],\n",
      "        [0.8302, 0.2003, 0.5052]]) torch.Size([2, 3]) torch.float32\n",
      "\n",
      "\n",
      "tensor([[ 2.0041, -0.0551,  1.4880],\n",
      "        [-0.5075,  1.0443, -0.8530]]) torch.Size([2, 3]) torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#takes in dims\n",
    "describe(torch.rand(2,3))\n",
    "#takes in dims\n",
    "describe(torch.randn(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f9dff409-fbcb-4b60-9b35-c902314b64cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([1, 2, 3, 4]) torch.Size([4]) torch.int64\n",
      "\n",
      "\n",
      "tensor([1., 3., 5., 7., 9.]) torch.Size([5]) torch.float32\n",
      "\n",
      "\n",
      "tensor([1.0000, 1.4444, 1.8889, 2.3333, 2.7778, 3.2222, 3.6667, 4.1111, 4.5556,\n",
      "        5.0000]) torch.Size([10]) torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#min max interval and max is excluded\n",
    "describe(torch.arange(1,5))\n",
    "describe(torch.arange(1.0,10.0,2))\n",
    "\n",
    "#min max number_of_values and max is included\n",
    "describe(torch.linspace(1,5,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e09bd4c-79fe-49dd-bf7c-78add462609d",
   "metadata": {},
   "source": [
    "## Functions where a tensor is altered(reshape,squeeze,unsqueeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bda396e8-b4b3-4510-b9a2-0b1e66e5b7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7]) torch.Size([8]) torch.int64\n",
      "\n",
      "\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]]) torch.Size([2, 4]) torch.int64\n",
      "\n",
      "tensor([[[0.6431, 0.7386],\n",
      "         [0.2529, 0.5463],\n",
      "         [0.8872, 0.2032]],\n",
      "\n",
      "        [[0.5340, 0.5104],\n",
      "         [0.9807, 0.1679],\n",
      "         [0.0379, 0.5528]],\n",
      "\n",
      "        [[0.2201, 0.2503],\n",
      "         [0.5550, 0.8240],\n",
      "         [0.3631, 0.3262]],\n",
      "\n",
      "        [[0.3391, 0.5989],\n",
      "         [0.3123, 0.4197],\n",
      "         [0.9391, 0.2328]]])\n",
      "\n",
      "tensor([[0.6431, 0.7386, 0.2529, 0.5463, 0.8872, 0.2032],\n",
      "        [0.5340, 0.5104, 0.9807, 0.1679, 0.0379, 0.5528],\n",
      "        [0.2201, 0.2503, 0.5550, 0.8240, 0.3631, 0.3262],\n",
      "        [0.3391, 0.5989, 0.3123, 0.4197, 0.9391, 0.2328]]) torch.Size([4, 6]) torch.float32\n",
      "\n",
      "\n",
      "tensor([[0.6431, 0.7386, 0.2529, 0.5463, 0.8872, 0.2032],\n",
      "        [0.5340, 0.5104, 0.9807, 0.1679, 0.0379, 0.5528],\n",
      "        [0.2201, 0.2503, 0.5550, 0.8240, 0.3631, 0.3262],\n",
      "        [0.3391, 0.5989, 0.3123, 0.4197, 0.9391, 0.2328]]) torch.Size([4, 6]) torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#reshaping starts from the innermost dimension\n",
    "#traverse on a flat tensor and start accumulating the innermost dimension\n",
    "#0,1,2,3(for the dimension 4 in (2,4))\n",
    "d = torch.arange(8)\n",
    "describe(d)\n",
    "describe(d.reshape(2,4))\n",
    "\n",
    "e = torch.rand((4,3,2))\n",
    "print(e)\n",
    "#they both yeild the same output\n",
    "describe(e.reshape(4,6))\n",
    "describe(e.reshape(-1).reshape(4,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06d5620a-1f3c-42b2-aa17-1956d6b3fef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[[0.6097, 0.2096],\n",
      "         [0.3063, 0.7557],\n",
      "         [0.9053, 0.1049]]]) torch.Size([1, 3, 2]) torch.float32\n",
      "\n",
      "\n",
      "tensor([[0.6097, 0.2096],\n",
      "        [0.3063, 0.7557],\n",
      "        [0.9053, 0.1049]]) torch.Size([3, 2]) torch.float32\n",
      "\n",
      "\n",
      "tensor([[[0.0119, 0.7893]],\n",
      "\n",
      "        [[0.3025, 0.0688]],\n",
      "\n",
      "        [[0.9503, 0.6213]]]) torch.Size([3, 1, 2]) torch.float32\n",
      "\n",
      "\n",
      "tensor([[0.0119, 0.7893],\n",
      "        [0.3025, 0.0688],\n",
      "        [0.9503, 0.6213]]) torch.Size([3, 2]) torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#gets rid of the dim if it is 1\n",
    "f = torch.rand(1,3,2)\n",
    "describe(f)\n",
    "describe(torch.squeeze(f,dim=0))\n",
    "\n",
    "g = torch.rand(3,1,2)\n",
    "describe(g)\n",
    "describe(torch.squeeze(g,dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2b7736ff-45b7-4a7a-8192-323b059f0993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[0.4634, 0.7433],\n",
      "        [0.5654, 0.0455],\n",
      "        [0.7890, 0.0802]]) torch.Size([3, 2]) torch.float32\n",
      "\n",
      "\n",
      "tensor([[[0.4634, 0.7433],\n",
      "         [0.5654, 0.0455],\n",
      "         [0.7890, 0.0802]]]) torch.Size([1, 3, 2]) torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#adds a dimension on dim\n",
    "h = torch.rand(3,2)\n",
    "describe(h)\n",
    "describe(torch.unsqueeze(h,dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bfcd43-18f6-4054-bb50-2dfe7df121e4",
   "metadata": {},
   "source": [
    "## Functions where two tensors are operated upon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8d777845-22b7-42be-9085-dbb475271973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) torch.Size([2, 3]) torch.int64\n",
      "\n",
      "\n",
      "tensor([[ 7,  8,  9],\n",
      "        [10, 11, 12]]) torch.Size([2, 3]) torch.int64\n",
      "\n",
      "dim=0 stacking\n",
      "\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]]) torch.Size([2, 2, 3]) torch.int64\n",
      "\n",
      "dim=1 stacking\n",
      "\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[ 4,  5,  6],\n",
      "         [10, 11, 12]]]) torch.Size([2, 2, 3]) torch.int64\n",
      "\n",
      "dim=2 stacking\n",
      "\n",
      "tensor([[[ 1,  7],\n",
      "         [ 2,  8],\n",
      "         [ 3,  9]],\n",
      "\n",
      "        [[ 4, 10],\n",
      "         [ 5, 11],\n",
      "         [ 6, 12]]]) torch.Size([2, 3, 2]) torch.int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6]])\n",
    "b = torch.tensor([[7,8,9],[10,11,12]])\n",
    "describe(a)\n",
    "describe(b)\n",
    "\n",
    "#a new dimension is always created while using stack\n",
    "print(\"dim=0 stacking\")\n",
    "#this is similar to creating a batch comprising of a and b\n",
    "describe(torch.stack([a,b]))\n",
    "print(\"dim=1 stacking\")\n",
    "#this is similar to joining respective rows to create a new dimension\n",
    "describe(torch.stack([a,b],dim=1))\n",
    "print(\"dim=2 stacking\")\n",
    "#this is similar to element to element joining\n",
    "describe(torch.stack([a,b],dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "684ec61d-26f3-45c6-9012-325960680558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]]) torch.Size([2, 2, 3]) torch.int64\n",
      "\n",
      "\n",
      "tensor([[[13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[19, 20, 21],\n",
      "         [22, 23, 24]]]) torch.Size([2, 2, 3]) torch.int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2,3],[4,5,6]])\n",
    "b = torch.tensor([[7,8,9],[10,11,12]])\n",
    "describe(a)\n",
    "describe(b)\n",
    "\n",
    "#cat joins tensors along existing dimensions\n",
    "print(\"dim=0 stacking\")\n",
    "#simply concatinating row wise i.e. 4 rows and 3 columns in output\n",
    "describe(torch.cat([a,b],dim=0))\n",
    "print(\"dim=1 stacking\")\n",
    "#simply concatinating column wise i.e. 2 rows and 6 columns in output\n",
    "describe(torch.cat([a,b],dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c1b6d40-9b7f-40f4-8c80-854c156e6179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15, 16],\n",
      "         [17, 18, 19, 20],\n",
      "         [21, 22, 23, 24]]]) torch.Size([2, 3, 4]) torch.int64\n",
      "\n",
      "\n",
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [13, 14, 15, 16]],\n",
      "\n",
      "        [[ 5,  6,  7,  8],\n",
      "         [17, 18, 19, 20]],\n",
      "\n",
      "        [[ 9, 10, 11, 12],\n",
      "         [21, 22, 23, 24]]]) torch.Size([3, 2, 4]) torch.int64\n",
      "\n",
      "\n",
      "tensor([[[ 1,  5,  9],\n",
      "         [ 2,  6, 10],\n",
      "         [ 3,  7, 11],\n",
      "         [ 4,  8, 12]],\n",
      "\n",
      "        [[13, 17, 21],\n",
      "         [14, 18, 22],\n",
      "         [15, 19, 23],\n",
      "         [16, 20, 24]]]) torch.Size([2, 4, 3]) torch.int64\n",
      "\n",
      "\n",
      "tensor([[[ 1, 13],\n",
      "         [ 5, 17],\n",
      "         [ 9, 21]],\n",
      "\n",
      "        [[ 2, 14],\n",
      "         [ 6, 18],\n",
      "         [10, 22]],\n",
      "\n",
      "        [[ 3, 15],\n",
      "         [ 7, 19],\n",
      "         [11, 23]],\n",
      "\n",
      "        [[ 4, 16],\n",
      "         [ 8, 20],\n",
      "         [12, 24]]]) torch.Size([4, 3, 2]) torch.int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#2,3,4\n",
    "#visualize this as two sheets(depth) each sheet containing 3 rows and 4 columns. These sheets stand parallel to each other\n",
    "a = torch.tensor([[[1,2,3,4],[5,6,7,8],[9,10,11,12]],[[13,14,15,16],[17,18,19,20],[21,22,23,24]]])\n",
    "describe(a)\n",
    "\n",
    "\n",
    "#3,2,4\n",
    "#here we need to convert 3 sheets to 2 and each sheet would contain two rows and four columns\n",
    "#View the visualization of \"a\" from the top. We can visualize three sheets stacked on top of one another(new depth) with rows of respective sheets now combined as \n",
    "#rows of the respective new sheets.\n",
    "b = torch.transpose(a,0,1)\n",
    "describe(b)\n",
    "\n",
    "c = torch.transpose(a,1,2)\n",
    "describe(c)\n",
    "\n",
    "#here we need to convert 2 sheets into 4 sheets and each sheet would contain 3 rows and 2 columns\n",
    "#View the visualization of \"a\" from the side. We can visualize 4 sheets stacked one behind another with elements/columns of respective sheets now combined as \n",
    "#columns of the respective new sheets.\n",
    "d = torch.transpose(a,0,2)\n",
    "describe(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "663d01a9-0051-411e-af2c-3e2dab27705c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[[ 1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8],\n",
      "         [ 9, 10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15, 16],\n",
      "         [17, 18, 19, 20],\n",
      "         [21, 22, 23, 24]]]) torch.Size([2, 3, 4]) torch.int64\n",
      "\n",
      "\n",
      "tensor([[14, 16, 18, 20],\n",
      "        [22, 24, 26, 28],\n",
      "        [30, 32, 34, 36]]) torch.Size([3, 4]) torch.int64\n",
      "\n",
      "\n",
      "tensor([[[14, 16, 18, 20],\n",
      "         [22, 24, 26, 28],\n",
      "         [30, 32, 34, 36]]]) torch.Size([1, 3, 4]) torch.int64\n",
      "\n",
      "\n",
      "tensor([[15, 18, 21, 24],\n",
      "        [51, 54, 57, 60]]) torch.Size([2, 4]) torch.int64\n",
      "\n",
      "\n",
      "tensor([[[15, 18, 21, 24]],\n",
      "\n",
      "        [[51, 54, 57, 60]]]) torch.Size([2, 1, 4]) torch.int64\n",
      "\n",
      "\n",
      "tensor([[10, 26, 42],\n",
      "        [58, 74, 90]]) torch.Size([2, 3]) torch.int64\n",
      "\n",
      "\n",
      "tensor([[[10],\n",
      "         [26],\n",
      "         [42]],\n",
      "\n",
      "        [[58],\n",
      "         [74],\n",
      "         [90]]]) torch.Size([2, 3, 1]) torch.int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[1,2,3,4],[5,6,7,8],[9,10,11,12]],[[13,14,15,16],[17,18,19,20],[21,22,23,24]]])\n",
    "describe(a)\n",
    "\n",
    "#sum along the outermost dim(along batch)\n",
    "#keepdim=False squeezes the dim that converts to 1 on sum\n",
    "describe(torch.sum(a,dim=0,keepdim=False))\n",
    "describe(torch.sum(a,dim=0,keepdim=True))\n",
    "\n",
    "#sum along the rows\n",
    "describe(torch.sum(a,dim=1,keepdim=False))\n",
    "describe(torch.sum(a,dim=1,keepdim=True))\n",
    "\n",
    "#sum along the columns\n",
    "describe(torch.sum(a,dim=2,keepdim=False))\n",
    "describe(torch.sum(a,dim=2,keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3a23892f-3f5f-4585-add6-dd9f236a8628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[3.3697e-01, 2.0672e-01, 7.0715e-01, 9.5798e-02, 4.7415e-01,\n",
      "           8.4588e-01, 3.6443e-01, 7.0721e-01],\n",
      "          [7.9038e-01, 2.6720e-01, 6.0252e-01, 8.0661e-01, 9.7861e-01,\n",
      "           9.3530e-01, 9.8666e-01, 3.4964e-01],\n",
      "          [6.9719e-01, 4.2518e-01, 1.7698e-01, 8.9443e-01, 6.6520e-01,\n",
      "           8.1274e-01, 3.8257e-01, 1.0800e-01],\n",
      "          [4.5931e-02, 1.2105e-01, 5.6327e-01, 2.9143e-01, 1.8205e-01,\n",
      "           6.4921e-01, 7.9034e-01, 1.9662e-02],\n",
      "          [7.8112e-01, 6.9247e-01, 9.8113e-01, 5.7140e-01, 1.3768e-01,\n",
      "           4.1122e-01, 2.3906e-01, 9.9297e-01],\n",
      "          [6.4141e-02, 8.8003e-02, 6.7621e-04, 6.9288e-01, 1.7235e-01,\n",
      "           1.2055e-01, 7.1414e-01, 9.3480e-01],\n",
      "          [3.9432e-01, 2.2759e-01, 3.8004e-01, 5.5961e-01, 5.4823e-01,\n",
      "           1.5178e-01, 8.0643e-01, 7.3773e-01],\n",
      "          [1.9700e-01, 4.9599e-01, 7.4360e-01, 7.9493e-01, 5.7901e-01,\n",
      "           4.2748e-01, 6.9591e-01, 1.5630e-02]],\n",
      "\n",
      "         [[5.3708e-01, 7.0153e-01, 4.5942e-01, 8.7917e-01, 7.4290e-01,\n",
      "           4.7378e-01, 3.7227e-01, 7.3104e-01],\n",
      "          [1.9044e-01, 9.9790e-01, 8.5011e-02, 8.5702e-01, 4.9770e-01,\n",
      "           2.0445e-01, 3.0644e-01, 1.4323e-03],\n",
      "          [6.8173e-01, 3.0681e-01, 9.6125e-01, 3.8006e-01, 8.4659e-01,\n",
      "           3.4041e-02, 9.2196e-03, 5.7432e-01],\n",
      "          [5.0042e-01, 4.5329e-01, 7.2619e-01, 2.8293e-01, 8.7033e-01,\n",
      "           7.5002e-01, 9.0310e-01, 4.3610e-01],\n",
      "          [4.8059e-01, 8.4510e-01, 8.3435e-01, 4.0220e-02, 8.1876e-01,\n",
      "           9.6642e-01, 9.5008e-01, 8.7766e-01],\n",
      "          [9.2755e-01, 9.5268e-01, 1.1863e-01, 2.7203e-01, 1.5685e-02,\n",
      "           3.8555e-01, 2.3028e-01, 2.6455e-01],\n",
      "          [2.4079e-02, 4.4691e-01, 5.3850e-01, 4.0249e-01, 4.2721e-02,\n",
      "           9.1560e-01, 8.4171e-02, 8.8624e-01],\n",
      "          [1.5999e-01, 4.5338e-01, 9.9454e-01, 2.7221e-01, 9.5408e-01,\n",
      "           2.6902e-01, 4.1030e-01, 3.0788e-01]],\n",
      "\n",
      "         [[6.0501e-01, 6.9087e-01, 9.2936e-02, 3.0270e-01, 3.8887e-01,\n",
      "           1.3693e-01, 8.6507e-01, 3.0227e-01],\n",
      "          [8.8286e-01, 1.8782e-01, 9.0003e-01, 4.7168e-01, 4.6257e-01,\n",
      "           4.6424e-01, 9.5162e-01, 5.1011e-01],\n",
      "          [4.3626e-01, 8.8296e-01, 6.3751e-01, 1.8889e-01, 2.2096e-01,\n",
      "           9.3707e-01, 8.6756e-01, 7.8181e-01],\n",
      "          [2.9871e-01, 7.3092e-01, 2.3975e-01, 2.2735e-01, 9.2050e-01,\n",
      "           6.5288e-01, 4.1646e-01, 7.1745e-01],\n",
      "          [7.3355e-01, 7.1336e-01, 1.9945e-01, 6.1750e-03, 8.4607e-01,\n",
      "           4.6147e-01, 8.4763e-01, 4.8106e-01],\n",
      "          [9.8729e-01, 4.3294e-01, 7.8386e-01, 6.1462e-01, 6.3698e-01,\n",
      "           5.6425e-01, 9.3551e-01, 1.6454e-01],\n",
      "          [9.8306e-01, 5.9759e-01, 2.5916e-01, 7.1149e-01, 8.3715e-01,\n",
      "           3.5775e-01, 1.0917e-01, 7.5392e-01],\n",
      "          [2.8658e-01, 3.9095e-01, 6.7386e-02, 4.1366e-01, 5.2398e-01,\n",
      "           9.7716e-01, 3.2192e-01, 8.0574e-01]],\n",
      "\n",
      "         [[1.5497e-01, 3.0301e-01, 1.6571e-01, 1.0363e-01, 1.1278e-01,\n",
      "           1.7860e-01, 7.9865e-01, 2.8764e-01],\n",
      "          [1.0466e-01, 3.0497e-01, 4.8645e-01, 8.7201e-01, 9.8443e-01,\n",
      "           2.8074e-01, 3.0566e-01, 8.1229e-01],\n",
      "          [8.0512e-01, 3.1398e-01, 8.1877e-01, 8.9803e-01, 3.9374e-02,\n",
      "           7.5325e-01, 3.6307e-02, 8.5218e-01],\n",
      "          [4.8134e-01, 5.3841e-01, 7.7201e-01, 3.9808e-01, 3.9316e-02,\n",
      "           6.1156e-01, 3.5381e-01, 8.5878e-01],\n",
      "          [1.3106e-01, 7.6262e-01, 9.9843e-01, 8.0864e-01, 9.5676e-01,\n",
      "           5.0258e-01, 2.1512e-01, 3.4408e-01],\n",
      "          [1.8952e-01, 1.4198e-01, 3.4925e-03, 2.5618e-01, 6.4594e-01,\n",
      "           8.5938e-01, 5.7194e-01, 7.1949e-01],\n",
      "          [2.7268e-01, 9.4049e-02, 4.1453e-01, 5.8844e-01, 6.6635e-01,\n",
      "           1.3197e-01, 6.1772e-01, 8.5683e-01],\n",
      "          [1.9770e-01, 1.8904e-01, 9.1380e-01, 6.8360e-01, 4.3156e-01,\n",
      "           3.8675e-01, 6.6320e-01, 4.2112e-02]]]])\n",
      "tensor([[[[3.3697e-01,       -inf,       -inf,       -inf,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [7.9038e-01, 2.6720e-01,       -inf,       -inf,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [6.9719e-01, 4.2518e-01, 1.7698e-01,       -inf,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [4.5931e-02, 1.2105e-01, 5.6327e-01, 2.9143e-01,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [7.8112e-01, 6.9247e-01, 9.8113e-01, 5.7140e-01, 1.3768e-01,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [6.4141e-02, 8.8003e-02, 6.7621e-04, 6.9288e-01, 1.7235e-01,\n",
      "           1.2055e-01,       -inf,       -inf],\n",
      "          [3.9432e-01, 2.2759e-01, 3.8004e-01, 5.5961e-01, 5.4823e-01,\n",
      "           1.5178e-01, 8.0643e-01,       -inf],\n",
      "          [1.9700e-01, 4.9599e-01, 7.4360e-01, 7.9493e-01, 5.7901e-01,\n",
      "           4.2748e-01, 6.9591e-01, 1.5630e-02]],\n",
      "\n",
      "         [[5.3708e-01,       -inf,       -inf,       -inf,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [1.9044e-01, 9.9790e-01,       -inf,       -inf,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [6.8173e-01, 3.0681e-01, 9.6125e-01,       -inf,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [5.0042e-01, 4.5329e-01, 7.2619e-01, 2.8293e-01,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [4.8059e-01, 8.4510e-01, 8.3435e-01, 4.0220e-02, 8.1876e-01,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [9.2755e-01, 9.5268e-01, 1.1863e-01, 2.7203e-01, 1.5685e-02,\n",
      "           3.8555e-01,       -inf,       -inf],\n",
      "          [2.4079e-02, 4.4691e-01, 5.3850e-01, 4.0249e-01, 4.2721e-02,\n",
      "           9.1560e-01, 8.4171e-02,       -inf],\n",
      "          [1.5999e-01, 4.5338e-01, 9.9454e-01, 2.7221e-01, 9.5408e-01,\n",
      "           2.6902e-01, 4.1030e-01, 3.0788e-01]],\n",
      "\n",
      "         [[6.0501e-01,       -inf,       -inf,       -inf,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [8.8286e-01, 1.8782e-01,       -inf,       -inf,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [4.3626e-01, 8.8296e-01, 6.3751e-01,       -inf,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [2.9871e-01, 7.3092e-01, 2.3975e-01, 2.2735e-01,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [7.3355e-01, 7.1336e-01, 1.9945e-01, 6.1750e-03, 8.4607e-01,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [9.8729e-01, 4.3294e-01, 7.8386e-01, 6.1462e-01, 6.3698e-01,\n",
      "           5.6425e-01,       -inf,       -inf],\n",
      "          [9.8306e-01, 5.9759e-01, 2.5916e-01, 7.1149e-01, 8.3715e-01,\n",
      "           3.5775e-01, 1.0917e-01,       -inf],\n",
      "          [2.8658e-01, 3.9095e-01, 6.7386e-02, 4.1366e-01, 5.2398e-01,\n",
      "           9.7716e-01, 3.2192e-01, 8.0574e-01]],\n",
      "\n",
      "         [[1.5497e-01,       -inf,       -inf,       -inf,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [1.0466e-01, 3.0497e-01,       -inf,       -inf,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [8.0512e-01, 3.1398e-01, 8.1877e-01,       -inf,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [4.8134e-01, 5.3841e-01, 7.7201e-01, 3.9808e-01,       -inf,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [1.3106e-01, 7.6262e-01, 9.9843e-01, 8.0864e-01, 9.5676e-01,\n",
      "                 -inf,       -inf,       -inf],\n",
      "          [1.8952e-01, 1.4198e-01, 3.4925e-03, 2.5618e-01, 6.4594e-01,\n",
      "           8.5938e-01,       -inf,       -inf],\n",
      "          [2.7268e-01, 9.4049e-02, 4.1453e-01, 5.8844e-01, 6.6635e-01,\n",
      "           1.3197e-01, 6.1772e-01,       -inf],\n",
      "          [1.9770e-01, 1.8904e-01, 9.1380e-01, 6.8360e-01, 4.3156e-01,\n",
      "           3.8675e-01, 6.6320e-01, 4.2112e-02]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.6279, 0.3721, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4244, 0.3233, 0.2523, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.1987, 0.2142, 0.3333, 0.2539, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2236, 0.2046, 0.2731, 0.1813, 0.1175, 0.0000, 0.0000, 0.0000],\n",
       "          [0.1426, 0.1461, 0.1339, 0.2675, 0.1590, 0.1509, 0.0000, 0.0000],\n",
       "          [0.1338, 0.1133, 0.1319, 0.1579, 0.1561, 0.1050, 0.2021, 0.0000],\n",
       "          [0.0901, 0.1215, 0.1556, 0.1638, 0.1320, 0.1134, 0.1484, 0.0751]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.3084, 0.6916, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.3322, 0.2284, 0.4394, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2493, 0.2378, 0.3124, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.1692, 0.2436, 0.2410, 0.1089, 0.2373, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2517, 0.2581, 0.1121, 0.1307, 0.1011, 0.1464, 0.0000, 0.0000],\n",
       "          [0.0982, 0.1500, 0.1643, 0.1434, 0.1001, 0.2396, 0.1043, 0.0000],\n",
       "          [0.0867, 0.1163, 0.1997, 0.0970, 0.1918, 0.0967, 0.1114, 0.1005]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.6671, 0.3329, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2641, 0.4129, 0.3230, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2265, 0.3490, 0.2136, 0.2109, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2399, 0.2351, 0.1406, 0.1159, 0.2685, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2253, 0.1294, 0.1838, 0.1552, 0.1587, 0.1476, 0.0000, 0.0000],\n",
       "          [0.2108, 0.1434, 0.1022, 0.1607, 0.1822, 0.1128, 0.0880, 0.0000],\n",
       "          [0.0997, 0.1107, 0.0801, 0.1132, 0.1264, 0.1989, 0.1033, 0.1676]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4501, 0.5499, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.3809, 0.2331, 0.3861, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.2317, 0.2453, 0.3098, 0.2132, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.1051, 0.1977, 0.2502, 0.2070, 0.2400, 0.0000, 0.0000, 0.0000],\n",
       "          [0.1354, 0.1291, 0.1124, 0.1447, 0.2137, 0.2646, 0.0000, 0.0000],\n",
       "          [0.1231, 0.1030, 0.1419, 0.1688, 0.1825, 0.1069, 0.1738, 0.0000],\n",
       "          [0.0945, 0.0937, 0.1934, 0.1536, 0.1194, 0.1141, 0.1505, 0.0809]]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn = torch.rand(1,4,8,8)\n",
    "print(attn)\n",
    "attn = attn.masked_fill(torch.tril(torch.ones(8,8)).view(1,1,8,8)[:,:,:8,:8] == 0,float('-inf'))\n",
    "print(attn)\n",
    "torch.nn.functional.softmax(attn,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f09c2f-913d-459f-b496-c4e670cf2e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
